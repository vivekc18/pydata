{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ce8e6b",
   "metadata": {},
   "source": [
    "# Machine Learning pipeline:Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b060e",
   "metadata": {},
   "source": [
    "## Supervised Learning: \n",
    "## What is Regression?\n",
    "## Types of regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94a45d",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/supervised-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23eda36",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/regression-analysis-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d766c",
   "metadata": {},
   "source": [
    "## Regularization in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54775f2c",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/regularization-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed33b0a",
   "metadata": {},
   "source": [
    "## Real-Life Applications - T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "740a8f51",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad298e4",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/linear-regression-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbfce1b",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df43699",
   "metadata": {},
   "source": [
    "### 1.simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492c906",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/simple-linear-regression-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032badd9",
   "metadata": {},
   "source": [
    "### 2.Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55215dc",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/multiple-linear-regression-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804a115",
   "metadata": {},
   "source": [
    "### 3.Polynomial linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8300e3",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/machine-learning-polynomial-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271907ad",
   "metadata": {},
   "source": [
    "### Applications of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083408c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f676e41c",
   "metadata": {},
   "source": [
    "## Regression equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ee9a5",
   "metadata": {},
   "source": [
    "### Y= mX+b  + ε\n",
    "    Here, Y = dependent variables (target variables),\n",
    "    X= Independent variables (predictor variables),\n",
    "    m Linear regression coefficient (scale factor to each input value).\n",
    "    b intercept of the line (Gives an additional degree of freedom)\n",
    "    ε is random error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf6e8e",
   "metadata": {},
   "source": [
    "## student score based on study hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a77c4",
   "metadata": {},
   "source": [
    "## Create a model to analyses the relation between CIE and SEE result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faecdc5",
   "metadata": {},
   "source": [
    "## Create a model to analyze the relation between crop yield and rain fall rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28709f60",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483329d7",
   "metadata": {},
   "source": [
    "#### Linear relationship between the features and target:\n",
    "* Linear regression assumes the linear relationship between the dependent and independent variables.\n",
    "\n",
    "#### Small or no multicollinearity between the features:\n",
    "* Multicollinearity means high-correlation between the independent variables. Due to multicollinearity, it may difficult to find the true relationship between the predictors and target variables. Or we can say, it is difficult to determine which predictor variable is affecting the target variable and which is not. So, the model assumes either little or no multicollinearity between the features or independent variables.\n",
    "\n",
    "#### Homoscedasticity Assumption:\n",
    "* Homoscedasticity is a situation when the error term is the same for all the values of independent variables. With homoscedasticity, there should be no clear pattern distribution of data in the scatter plot.\n",
    "\n",
    "#### Normal distribution of error terms:\n",
    "* Linear regression assumes that the error term should follow the normal distribution pattern. If error terms are not normally distributed, then confidence intervals will become either too wide or too narrow, which may cause difficulties in finding coefficients.\n",
    "* It can be checked using the q-q plot. If the plot shows a straight line without any deviation, which means the error is normally distributed.\n",
    "\n",
    "#### No autocorrelations:\n",
    "* The linear regression model assumes no autocorrelation in error terms. If there will be any correlation in the error term, then it will drastically reduce the accuracy of the model. Autocorrelation usually occurs if there is a dependency between residual errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035c496",
   "metadata": {},
   "source": [
    "## Cost Function & Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b216be1",
   "metadata": {},
   "source": [
    "Finding the best fit line:\n",
    "When working with linear regression, our main goal is to find the best fit line that means the error between predicted values and actual values should be minimized. The best fit line will have the least error.\n",
    "\n",
    "The different values for weights or the coefficient of lines (a0, a1) gives a different line of regression, so we need to calculate the best values for a0 and a1 to find the best fit line, so to calculate this we use cost function.\n",
    "\n",
    "Cost function-\n",
    "The different values for weights or coefficient of lines (a0, a1) gives the different line of regression, and the cost function is used to estimate the values of the coefficient for the best fit line.\n",
    "Cost function optimizes the regression coefficients or weights. It measures how a linear regression model is performing.\n",
    "We can use the cost function to find the accuracy of the mapping function, which maps the input variable to the output variable. This mapping function is also known as Hypothesis function.\n",
    "For Linear Regression, we use the Mean Squared Error (MSE) cost function, which is the average of squared error occurred between the predicted values and actual values. It can be written as:\n",
    "\n",
    "\n",
    "For the above linear equation, MSE can be calculated as:\n",
    "\n",
    "Linear Regression in Machine Learning\n",
    "Where,\n",
    "\n",
    "N=Total number of observation\n",
    "Yi = Actual value\n",
    "(a1xi+a0)= Predicted value.\n",
    "\n",
    "Residuals: The distance between the actual value and predicted values is called residual. If the observed points are far from the regression line, then the residual will be high, and so cost function will high. If the scatter points are close to the regression line, then the residual will be small and hence the cost function.\n",
    "\n",
    "Gradient Descent:\n",
    "Gradient descent is used to minimize the MSE by calculating the gradient of the cost function.\n",
    "A regression model uses gradient descent to update the coefficients of the line by reducing the cost function.\n",
    "It is done by a random selection of values of coefficient and then iteratively update the values to reach the minimum cost function.\n",
    "Model Performance:\n",
    "The Goodness of fit determines how the line of regression fits the set of observations. The process of finding the best model out of various models is called optimization. It can be achieved by below method:\n",
    "\n",
    "\n",
    "1. R-squared method:\n",
    "\n",
    "R-squared is a statistical method that determines the goodness of fit.\n",
    "It measures the strength of the relationship between the dependent and independent variables on a scale of 0-100%.\n",
    "The high value of R-square determines the less difference between the predicted values and actual values and hence represents a good model.\n",
    "It is also called a coefficient of determination, or coefficient of multiple determination for multiple regression.\n",
    "It can be calculated from the below formula:\n",
    "Linear Regression in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc850dfb",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44655c1",
   "metadata": {},
   "source": [
    "## Why do we need Cross-Validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbed88",
   "metadata": {},
   "source": [
    "## Techniques\n",
    "* Hold out method\n",
    "* Leave One Out Cross-Validation\n",
    "* K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42bc00",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/cross-validation-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e6136",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "* Overview\n",
    "* Assumptions\n",
    "* Normal Equation\n",
    "* Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2022f",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/multiple-linear-regression-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b8083",
   "metadata": {},
   "source": [
    "### Boston housing price from sci-kit learn datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9908e0d",
   "metadata": {},
   "source": [
    "## Cricket match result - past data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1717b8b",
   "metadata": {},
   "source": [
    "## Performance of a cricket player - past data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45263f0b",
   "metadata": {},
   "source": [
    "## Crop yield - past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af808338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
